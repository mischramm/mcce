

\section{General definitions} \label{cha:generalDefinitions}

\subsection{What is Kubernetes and its area of use?}

Kubernetes, often abbreviated as K8s, is an open-source platform designed to automate the deployment, scaling, and management of containerized applications. Since its introduction in 2014, Kubernetes has become the dominant tool for container orchestration, widely adopted by organizations across industries. Its origins can be traced back to Google’s internal system, Borg, which had been used for over a decade to manage containerized workloads in Google’s data centers. Kubernetes builds on the principles of Borg, such as declarative configuration, automated scheduling, and self-healing capabilities, to provide a robust and scalable solution for managing modern cloud-native applications \citeyear{rahman2023, deng2023}.

The primary purpose of Kubernetes is to abstract the complexities of managing containerized applications, enabling developers to focus on application development rather than the underlying infrastructure. By automating tasks such as deployment, scaling, and failover, Kubernetes reduces operational overhead and improves the reliability and scalability of applications. This automation is particularly valuable in cloud-native environments, where applications are often distributed across multiple nodes and require dynamic resource allocation to meet changing demands \citeyear{carrion2023, nadaf2022}.

Kubernetes operates on a cluster-based architecture, which consists of a control plane and worker nodes. The control plane, often referred to as the master node, is responsible for managing the state of the cluster. It includes components such as the API server, which serves as the interface for interacting with the cluster, the scheduler, which assigns workloads to nodes, and the controller manager, which ensures that the desired state of the system is maintained. Worker nodes, on the other hand, are responsible for running the containerized applications. Each worker node includes a container runtime, such as Docker or containerd, a kubelet, which communicates with the control plane, and a kube-proxy, which manages networking within the cluster \citeyear{nadaf2022}.

At the heart of Kubernetes is the concept of a pod, which is the smallest deployable unit in the system. A pod encapsulates one or more containers that share the same network namespace and storage resources. This design allows Kubernetes to manage tightly coupled application components as a single unit, simplifying the deployment and scaling of complex applications. In addition to pods, Kubernetes provides several other abstractions, such as services, which enable load balancing and service discovery, and ConfigMaps and Secrets, which allow for the secure management of application configuration and sensitive data \citeyear{rahman2023}.

The adoption of Kubernetes has been driven by its ability to support a wide range of use cases. One of its most significant applications is in the management of microservices architectures, where each service is deployed as a separate container. Kubernetes simplifies the orchestration of these services, providing features such as service discovery, load balancing, and rolling updates. This makes it an ideal platform for building scalable and resilient applications. Another common use case is in continuous integration and continuous deployment (CI/CD) pipelines, where Kubernetes enables the automated testing, deployment, and scaling of applications. Tools such as Jenkins, GitLab CI/CD, and ArgoCD are often used in conjunction with Kubernetes to implement GitOps workflows, which further streamline the development process \citeyear{cncf2021}.

Beyond traditional application development, Kubernetes is increasingly being used in emerging fields such as big data and machine learning. Its ability to manage distributed workloads makes it a natural fit for running frameworks like Apache Spark and TensorFlow, which require significant computational resources. Kubernetes also plays a critical role in edge computing, where applications are deployed closer to the end user to reduce latency. Lightweight Kubernetes distributions, such as K3s, have been developed specifically for edge environments, enabling the deployment of containerized applications on resource-constrained devices \citeyear{deng2023}.

The flexibility and scalability of Kubernetes have made it a popular choice for organizations of all sizes. According to the CNCF Annual Survey (2021), 96\% of respondents reported that their organizations were either using Kubernetes or planning to adopt it. Furthermore, 69\% of respondents indicated that they were already using Kubernetes in production. This widespread adoption is a testament to the platform’s ability to meet the needs of modern software development. However, the survey also highlighted some challenges associated with Kubernetes, particularly in the area of security. For example, 44\% of respondents reported delaying the deployment of applications due to security concerns, and 95\% indicated that they had experienced a security incident involving Kubernetes \citeyear{cncf2021}.

The security challenges associated with Kubernetes are largely due to its complexity and the potential for misconfigurations. Misconfigurations in Kubernetes manifests, such as excessive permissions and insecure default settings, are a common source of vulnerabilities. These issues can lead to unauthorized access, privilege escalation, and data breaches. For example, in 2018, attackers gained unauthorized access to Tesla’s AWS environment through an unsecured Kubernetes dashboard. Similarly, the Capital One data breach in 2019, which affected over 100 million customers, was attributed to a Kubernetes misconfiguration \citeyear{shamim2021, khan2023}. These incidents underscore the importance of securing Kubernetes environments to prevent similar breaches.

Despite these challenges, Kubernetes offers several advantages that have contributed to its widespread adoption. One of its most significant benefits is its ability to improve resource utilization by dynamically scheduling workloads based on resource availability and requirements. This ensures that applications can scale efficiently to meet changing demands. Kubernetes also enhances developer productivity by abstracting the complexities of infrastructure management, allowing developers to focus on writing code and delivering features. Additionally, Kubernetes provides resilience and high availability, ensuring that applications remain operational even in the face of hardware or software failures. Finally, as an open-source platform, Kubernetes is vendor-neutral, enabling organizations to deploy applications across multiple cloud providers or on-premises environments without the risk of vendor lock-in \citeyear{carrion2023, nadaf2022}.

In conclusion, Kubernetes has revolutionized the way applications are deployed and managed in modern IT environments. Its ability to automate complex operational tasks, coupled with its extensibility and scalability, has made it an essential tool for organizations embracing cloud-native technologies. However, as the adoption of Kubernetes continues to grow, it is crucial to address the security challenges associated with the platform to ensure its long-term viability. By leveraging best practices and innovative tools, such as Security Orchestration, Automation, and Response (SOAR) systems, organizations can enhance the security of their Kubernetes environments while maintaining the performance and scalability that have made the platform so popular.

\subsection{Kubernetes in the context of IT Security}

Kubernetes has become a cornerstone of modern cloud-native application development, offering unparalleled flexibility and scalability for managing containerized workloads. However, its widespread adoption has also introduced significant security challenges. As organizations increasingly rely on Kubernetes to deploy and manage their applications, the platform has become a prime target for cyberattacks. The complexity of Kubernetes, combined with its extensive configurability, has made it particularly vulnerable to misconfigurations and other security risks. These vulnerabilities, if left unaddressed, can lead to severe consequences, including unauthorized access, data breaches, and service disruptions \citep{rahman2023, shamim2021}.

One of the most critical security challenges in Kubernetes environments is the prevalence of misconfigurations in Kubernetes manifests. Kubernetes manifests are declarative configuration files that define the desired state of the system, including the deployment of applications, resource allocation, and access controls. While these manifests provide a powerful mechanism for managing complex systems, they are also prone to errors. Misconfigurations, such as granting excessive permissions, exposing sensitive data, or failing to enforce network policies, are a common source of vulnerabilities. Rahman et al. (\citeyear{rahman2023}) conducted an empirical study analyzing over 2,000 Kubernetes manifests from open-source repositories and found that misconfigurations were widespread. Their findings revealed that many developers lack the necessary expertise to configure Kubernetes securely, leading to a high frequency of security issues. To address this problem, the authors developed SLI-KUBE, a tool designed to detect and mitigate misconfigurations in Kubernetes manifests. SLI-KUBE provides actionable recommendations to improve the security posture of Kubernetes environments, highlighting the importance of automated tools in reducing human error.

In addition to misconfigurations, Kubernetes is susceptible to a variety of cyberattacks, including distributed denial-of-service (DDoS) attacks and privilege escalation. DDoS attacks, in particular, pose a significant threat to Kubernetes clusters, as they can exploit the platform's auto-scaling mechanisms to exhaust resources. Lee et al. (\citeyear{lee2023}) investigated the vulnerability of Kubernetes to YoYo attacks, a type of DDoS attack that repeatedly triggers the auto-scaling of resources, causing resource exhaustion and service degradation. Their study demonstrated that while Kubernetes exhibits better resilience to such attacks compared to traditional virtual machines, it remains vulnerable to resource exhaustion under sustained attack. To mitigate this risk, the authors proposed a machine learning-based detection mechanism using the XGBoost classifier, which significantly improves the accuracy of attack detection. This approach highlights the potential of artificial intelligence and machine learning in enhancing the security of Kubernetes environments.

Privilege escalation is another critical security concern in Kubernetes. Attackers can exploit misconfigured role-based access control (RBAC) policies or vulnerabilities in container runtimes to gain unauthorized access to sensitive resources. Once inside the cluster, attackers can move laterally, compromise additional resources, and exfiltrate data. The complexity of Kubernetes' access control mechanisms often makes it challenging for administrators to enforce the principle of least privilege, further exacerbating the risk of privilege escalation. Tools like SLI-KUBE and other automated security solutions can help identify and remediate these issues, but a comprehensive approach to security is necessary to address the root causes of these vulnerabilities \citep{rahman2023}.

Real-world incidents provide stark examples of the consequences of security lapses in Kubernetes environments. One of the most notable cases is the Tesla AWS breach in 2018, where attackers gained unauthorized access to Tesla's cloud infrastructure through an unsecured Kubernetes dashboard. The attackers exploited the misconfigured dashboard to mine cryptocurrency, causing financial and reputational damage to the company. This incident underscores the importance of securing Kubernetes dashboards and other administrative interfaces, which are often overlooked in security assessments. Shamim (\citeyear{shamim2021}) analyzed the Tesla breach and highlighted the need for stricter access controls, network segmentation, and regular security audits to prevent similar incidents.

Another high-profile case is the Capital One data breach in 2019, which affected over 100 million customers in the United States and Canada. The breach was attributed to a misconfigured Kubernetes environment that allowed an attacker to exploit a vulnerability in a web application firewall. The attacker gained access to sensitive customer data, including social security numbers and bank account details. Khan et al. (\citeyear{khan2023}) conducted a systematic analysis of the Capital One breach, examining the technical and organizational factors that contributed to the incident. Their findings revealed that the breach was not only a result of technical misconfigurations but also a failure of organizational processes, such as inadequate training and oversight. The study emphasized the need for a holistic approach to Kubernetes security, combining technical measures with organizational best practices.

To address the growing security challenges in Kubernetes environments, researchers and practitioners have proposed a range of mitigation strategies. Automated tools, such as SLI-KUBE, play a crucial role in detecting and remediating misconfigurations, reducing the likelihood of human error. Machine learning-based approaches, like the XGBoost classifier proposed by Lee et al. (\citeyear{lee2023}), offer promising solutions for detecting and mitigating advanced threats, such as DDoS attacks. These tools can analyze large volumes of data in real-time, enabling faster and more accurate threat detection. However, the effectiveness of these solutions depends on their integration into a broader security framework that includes regular audits, access controls, and incident response plans.

In addition to technical solutions, organizations must invest in training and education to improve the security awareness of their teams. Many of the vulnerabilities in Kubernetes environments stem from a lack of understanding of the platform's security features and best practices. Providing developers and administrators with the knowledge and tools they need to configure Kubernetes securely is essential for reducing the risk of misconfigurations and other security issues. Furthermore, organizations should adopt a defense-in-depth approach to security, implementing multiple layers of protection to safeguard their Kubernetes environments from a wide range of threats.

In conclusion, Kubernetes has transformed the way organizations deploy and manage applications, but its complexity and configurability have introduced significant security challenges. Misconfigurations, DDoS attacks, and privilege escalation are among the most pressing issues facing Kubernetes users today. Real-world incidents, such as the Tesla AWS breach and the Capital One data breach, highlight the severe consequences of security lapses in Kubernetes environments. To address these challenges, organizations must adopt a comprehensive approach to security, combining automated tools, machine learning-based solutions, and best practices. By doing so, they can mitigate the risks associated with Kubernetes and ensure the security and reliability of their applications.

\subsection{SOAR - Next generation SOC}

The increasing sophistication of cyberattacks and the growing complexity of IT environments have necessitated the development of advanced security solutions. Security Orchestration, Automation, and Response (SOAR) tools represent the next generation of IT security technologies, designed to address the limitations of traditional security systems. Introduced in 2017, SOAR tools have rapidly gained attention for their ability to enhance the efficiency and effectiveness of Security Operations Centers (SOCs). These tools are considered an evolution of Security Information and Event Management (SIEM) systems, offering additional capabilities such as orchestration, automation, and structured workflows. By integrating disparate tools and data sources, automating incident response, and standardizing workflows, SOAR tools aim to streamline security operations and reduce the burden on SOC operators \citep{empl2022, katsikas2022}.

The evolution from SIEM to SOAR reflects a shift in focus from merely collecting and analyzing security data to actively responding to threats. While SIEM systems are primarily designed to aggregate and correlate security events from multiple sources, they often generate an overwhelming volume of alerts, many of which are false positives. This "alert fatigue" can hinder the ability of SOC analysts to identify and respond to genuine threats in a timely manner. SOAR tools address this challenge by automating routine tasks, prioritizing alerts, and providing actionable insights. This not only reduces the workload for SOC operators but also improves the speed and accuracy of incident response. As a result, SOAR tools have become an essential component of modern SOCs, enabling organizations to keep pace with the evolving threat landscape \citep{bridges2023}.

One of the defining features of SOAR tools is their ability to orchestrate security operations by unifying disparate tools and data sources into a cohesive system. In a typical SOC, analysts rely on a wide range of tools, including firewalls, intrusion detection systems, endpoint protection platforms, and threat intelligence feeds. Managing these tools individually can be time-consuming and error-prone, particularly in large and complex environments. SOAR tools address this challenge by providing a centralized platform that integrates these tools and facilitates seamless communication between them. This orchestration capability simplifies the investigation of security incidents, enabling analysts to access all relevant information in one place and make more informed decisions \citep{empl2022, katsikas2022}.

Automation is another key feature of SOAR tools, aimed at reducing the manual effort required for incident response. Many tasks performed by SOC analysts, such as triaging alerts, gathering contextual information, and executing remediation actions, are repetitive and time-consuming. By automating these tasks, SOAR tools free up analysts to focus on more strategic activities, such as threat hunting and proactive defense. For example, a SOAR tool can automatically isolate a compromised endpoint, block malicious IP addresses, or update firewall rules in response to a detected threat. This not only accelerates the response to security incidents but also minimizes the risk of human error, which is a common cause of security breaches \citep{bridges2023}.

In addition to orchestration and automation, SOAR tools provide structured workflows known as playbooks, which standardize and accelerate the incident response process. Playbooks are predefined sets of actions that guide analysts through the steps required to investigate and remediate specific types of incidents. For example, a playbook for a phishing attack might include steps such as analyzing the email header, extracting and scanning attachments, and blocking the sender's domain. By providing a consistent and repeatable approach to incident response, playbooks help ensure that best practices are followed and that incidents are resolved efficiently. Furthermore, playbooks can be customized to meet the specific needs of an organization, making them a versatile tool for managing a wide range of security scenarios \citep{bridges2023}.

The relevance of SOAR tools to Kubernetes environments lies in their ability to address the unique security challenges posed by containerized applications. Kubernetes has become the de facto standard for container orchestration, enabling organizations to deploy and manage applications at scale. However, its complexity and configurability have made it a prime target for cyberattacks. Misconfigurations, privilege escalation, and distributed denial-of-service (DDoS) attacks are among the most common security issues in Kubernetes environments. SOAR tools can enhance Kubernetes security by automating threat detection and response, reducing the likelihood of human error, and providing a centralized platform for managing security operations \citep{empl2022}.

For example, a SOAR tool can be used to monitor Kubernetes logs for signs of suspicious activity, such as unauthorized access attempts or unusual resource usage. When a potential threat is detected, the tool can automatically trigger a response, such as revoking access, scaling down affected pods, or notifying the SOC team. This proactive approach to security is particularly valuable in Kubernetes environments, where the dynamic nature of containerized applications can make it difficult to detect and respond to threats manually. Furthermore, the integration of SOAR tools with Kubernetes can help organizations enforce security best practices, such as implementing role-based access control (RBAC) policies and ensuring that sensitive data is stored securely \citep{bridges2023}.

Despite their potential, SOAR tools are still a relatively new technology, and their adoption in Kubernetes environments is not yet widespread. One of the main barriers to adoption is the lack of empirical studies evaluating the effectiveness of SOAR tools in real-world scenarios. While several studies have demonstrated the benefits of SOAR tools in traditional IT environments, their application to Kubernetes remains underexplored. This gap in the research highlights the need for further studies to assess the impact of SOAR tools on the performance and security of Kubernetes clusters. Such studies could provide valuable insights for organizations considering the adoption of SOAR tools and help drive the development of best practices for their implementation \citep{empl2022, bridges2023}.

In conclusion, SOAR tools represent a significant advancement in IT security, offering capabilities that go beyond those of traditional SIEM systems. By integrating disparate tools and data sources, automating routine tasks, and providing structured workflows, SOAR tools enable SOCs to operate more efficiently and effectively. Their relevance to Kubernetes environments is particularly noteworthy, as they can help address the unique security challenges posed by containerized applications. However, further research is needed to fully understand the potential of SOAR tools in Kubernetes and to develop best practices for their implementation. As the adoption of Kubernetes continues to grow, the integration of SOAR tools could play a critical role in ensuring the security and reliability of containerized applications.

 \begin{itemize}
    \item Papers about Problem Solving Computational Models (PSCM)
\end{itemize}
